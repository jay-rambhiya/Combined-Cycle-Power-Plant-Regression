{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413a7c8a-9a06-4c59-b50b-87d94ae8eaa3",
   "metadata": {},
   "source": [
    "# Name : Jay Rambhiya\n",
    "\n",
    "# Git-Hub Username : jay-rambhiya\n",
    "\n",
    "# USC ID: #2219880371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7c0a26-d92d-4c5d-8407-71fccfb4360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors, KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef53c87-2f0b-4e8c-8cfe-f2623ef01e0e",
   "metadata": {},
   "source": [
    "# (1) (b) Exploring the data\n",
    "\n",
    "# i. Rows and Columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7681e62-3a41-4219-b41e-ca7923960f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>16.65</td>\n",
       "      <td>49.69</td>\n",
       "      <td>1014.01</td>\n",
       "      <td>91.00</td>\n",
       "      <td>460.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>13.19</td>\n",
       "      <td>39.18</td>\n",
       "      <td>1023.67</td>\n",
       "      <td>66.78</td>\n",
       "      <td>469.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>31.32</td>\n",
       "      <td>74.33</td>\n",
       "      <td>1012.92</td>\n",
       "      <td>36.48</td>\n",
       "      <td>429.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>24.48</td>\n",
       "      <td>69.45</td>\n",
       "      <td>1013.86</td>\n",
       "      <td>62.39</td>\n",
       "      <td>435.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>21.60</td>\n",
       "      <td>62.52</td>\n",
       "      <td>1017.23</td>\n",
       "      <td>67.87</td>\n",
       "      <td>453.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT      V       AP     RH      PE\n",
       "0     14.96  41.76  1024.07  73.17  463.26\n",
       "1     25.18  62.96  1020.04  59.08  444.37\n",
       "2      5.11  39.40  1012.16  92.14  488.56\n",
       "3     20.86  57.32  1010.24  76.64  446.48\n",
       "4     10.82  37.50  1009.23  96.62  473.90\n",
       "...     ...    ...      ...    ...     ...\n",
       "9563  16.65  49.69  1014.01  91.00  460.03\n",
       "9564  13.19  39.18  1023.67  66.78  469.62\n",
       "9565  31.32  74.33  1012.92  36.48  429.57\n",
       "9566  24.48  69.45  1013.86  62.39  435.74\n",
       "9567  21.60  62.52  1017.23  67.87  453.28\n",
       "\n",
       "[9568 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../Data/Folds5x2_pp.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6917acd4-6837-4cf4-a7c8-c40430561b96",
   "metadata": {},
   "source": [
    "# The dataset contains 9568 Rows which represent data collected from a Combined Cycle Power Plant over 6 years (2006-2011). There are 5 Columns which represent features like hourly average ambient variables Temperature (AT), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) and net hourly electrical energy output (EP)  of the plant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189459c-590c-4852-90e5-3c69916d8e1c",
   "metadata": {},
   "source": [
    "# Pairwise scatterplots of all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d00b70-0757-46bc-9dde-456d292c82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue = 'PE', palette='husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96710dd0-0838-48b9-98cd-3d3f4d858e0a",
   "metadata": {},
   "source": [
    "# From the above pair plot , we can see that PE value of the plant is low if the AT is low and vise versa. Also PE value of plant is low if V is low and vise versa. Nothing can be said for the remaining 2 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64ddc3-4ac5-4a88-83d2-00ce2ba9b44f",
   "metadata": {},
   "source": [
    "# iii. Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc2ffd-9883-4a1e-b597-b05d9a749331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.describe()\n",
    "df1.loc['range'] = df1.loc['max'] - df1.loc['min']\n",
    "df1.loc['interquartileRange'] = df1.loc['75%'] - df1.loc['25%']\n",
    "df1.loc['median'] = df1.loc['50%']\n",
    "df1.loc['firstquartile'] = df1.loc['25%']\n",
    "df1.loc['thirdquartile'] = df1.loc['75%']\n",
    "df1 = df1.loc[['mean', 'median', 'range', 'firstquartile', 'thirdquartile', 'interquartileRange'], :]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d856dd3-de52-4e7a-bc11-fd18a9a40a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987e310-cca3-4a15-ace4-c89c4cd3dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tabulate(df1, headers = df1.head(0), tablefmt = \"fancy_grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7823141-33ef-4242-8db9-75205dc95f82",
   "metadata": {},
   "source": [
    "# (1) (c) Simple Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead16285-5ccf-43ca-b2fb-f44b1df60ad0",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Model using AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d338649-7468-4448-93b0-d956d0474c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('PE~AT', df)\n",
    "linRegModelAT=model.fit()\n",
    "predictionAT = linRegModelAT.predict(df)\n",
    "linRegModelAT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc42ae-c10f-49b6-9e91-54d77c46b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['AT'], df['PE'], color = 'grey')\n",
    "plt.ylabel('PE')\n",
    "plt.xlabel('AT')\n",
    "plt.plot(df['AT'], predictionAT, color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0035c-29fd-460e-98bf-bd6bf749cc62",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Model using V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e7d80-8e65-4a03-9fd6-8ff4fea4a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('PE~V', df)\n",
    "linRegModelV=model.fit()\n",
    "predictionV = linRegModelV.predict(df)\n",
    "linRegModelV.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f0cf6-7d67-4236-9e2e-40e2bc9a3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['V'], df['PE'], color = 'grey')\n",
    "plt.ylabel('PE')\n",
    "plt.xlabel('V')\n",
    "plt.plot(df['V'], predictionV, color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0118a84-9673-4241-a764-072e40fc9c4b",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Model using AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba0bd9-dfc0-4570-8a8e-79500e44ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('PE~AP', df)\n",
    "linRegModelAP=model.fit()\n",
    "predictionAP = linRegModelAP.predict(df)\n",
    "linRegModelAP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be0961-e814-461b-9e27-e69f700075b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['AP'], df['PE'], color = 'grey')\n",
    "plt.ylabel('PE')\n",
    "plt.xlabel('AP')\n",
    "plt.plot(df['AP'], predictionAP, color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14dc80-f1c2-4656-938c-7fe4911eb25b",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Model using RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228a30d-fad4-4e47-aa6b-65b3a4664e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('PE~RH', df)\n",
    "linRegModelRH=model.fit()\n",
    "predictionRH = linRegModelRH.predict(df)\n",
    "linRegModelRH.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e46a1c-d51a-40d9-9a2a-252e4e64beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['RH'], df['PE'], color = 'grey')\n",
    "plt.ylabel('PE')\n",
    "plt.xlabel('RH')\n",
    "plt.plot(df['RH'], predictionRH, color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ab279-0167-492e-958f-52bcb7fb51b1",
   "metadata": {},
   "source": [
    "# From the above plots, we can see that the predictors have a relationship with the response. The p values for all the predictors are significantly less than threshold value which is 0.05. Hence, there is significant association between the dependent and independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef1d20-dba4-414d-b54b-4ac5489c16f4",
   "metadata": {},
   "source": [
    "# Outlier Analysis\n",
    "# Using the IQR, the outlier data points are the ones falling below Q1â€“1.5 IQR or above Q3 + 1.5 IQR. The Q1 is the 25th percentile and Q3 is the 75th percentile of the dataset, and IQR represents the interquartile range calculated by Q3 minus Q1 (Q3â€“Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1196a-dd9d-4357-8745-41dec49a0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundAT = df1.loc['firstquartile', 'AT'] - ((df1.loc['interquartileRange', 'AT']) * 1.5)\n",
    "upperBoundAT = df1.loc['thirdquartile', 'AT'] + ((df1.loc['interquartileRange', 'AT']) * 1.5)\n",
    "print('The upper bound for AT is:', upperBoundAT, 'and the lower bound for AT is', lowerBoundAT)\n",
    "print('The outliers for AT are as below:')\n",
    "df[(df['AT'] < lowerBoundAT) | (df['AT'] > upperBoundAT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a882a-283b-4dc9-9ed9-8335c6401be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundV = df1.loc['firstquartile', 'V'] - ((df1.loc['interquartileRange', 'V']) * 1.5)\n",
    "upperBoundV = df1.loc['thirdquartile', 'V'] + ((df1.loc['interquartileRange', 'V']) * 1.5)\n",
    "print('The upper bound for V is:', upperBoundV, 'and the lower bound for V is', lowerBoundV)\n",
    "print('The outliers for V are as below:')\n",
    "df[(df['V'] < lowerBoundV) | (df['V'] > upperBoundV)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00837aaf-39d9-421f-91af-b7ef02aae109",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundAP = df1.loc['firstquartile', 'AP'] - ((df1.loc['interquartileRange', 'AP']) * 1.5)\n",
    "upperBoundAP = df1.loc['thirdquartile', 'AP'] + ((df1.loc['interquartileRange', 'AP']) * 1.5)\n",
    "print('The upper bound for AP is:', upperBoundAP, 'and the lower bound for AP is', lowerBoundAP)\n",
    "print('The outliers for AP are as below:')\n",
    "df[(df['AP'] < lowerBoundAP) | (df['AP'] > upperBoundAP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7de943-0931-4462-ab13-61d41b4ce261",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundRH = df1.loc['firstquartile', 'RH'] - ((df1.loc['interquartileRange', 'RH']) * 1.5)\n",
    "upperBoundRH = df1.loc['thirdquartile', 'RH'] + ((df1.loc['interquartileRange', 'RH']) * 1.5)\n",
    "print('The upper bound for RH is:', upperBoundRH, 'and the lower bound for RH is', lowerBoundRH)\n",
    "print('The outliers for RH are as below:')\n",
    "df[(df['RH'] < lowerBoundRH) | (df['RH'] > upperBoundRH)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a4885-8c84-42b9-9b6f-31f296215c73",
   "metadata": {},
   "source": [
    "# From the above outlier analysis, we can see that there are some outliers for AP and RH. There are no outliers for AT and V. Removing these outliers will give us better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c09f2-99d7-42a0-bb00-d242f4db71b3",
   "metadata": {},
   "source": [
    "# (1) (d) Multiple Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1e8ee-9b28-46c8-84ce-052fa09c0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('PE~AT+V+AP+RH', df)\n",
    "multipleLinRegModel=model.fit()\n",
    "predictionMultiple = multipleLinRegModel.predict(df)\n",
    "multipleLinRegModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9a861-286f-4e22-8ddd-769e6c1b9f0c",
   "metadata": {},
   "source": [
    "# We can reject the null hypothesis for every predictor as each of the predictors has a p value less than threshold value which is 0.05 and every variable has a significant co-efficient value which affects the regression value.Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9a2a0-6a0f-48d6-b161-6996d8f7023d",
   "metadata": {},
   "source": [
    "# (1) (e) Comparing simple linear regression model and multiple linear regression model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2057c4-d825-4126-b5cd-6dec149cc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of AT in linear regression:', linRegModelAT.params[1], 'and in multiple regression:', multipleLinRegModel.params[1])\n",
    "print('Coefficient of V in linear regression:', linRegModelV.params[1], 'and in multiple regression:', multipleLinRegModel.params[2])\n",
    "print('Coefficient of AP in linear regression:', linRegModelAP.params[1], 'and in multiple regression:', multipleLinRegModel.params[3])\n",
    "print('Coefficient of RH in linear regression:', linRegModelRH.params[1], 'and in multiple regression:', multipleLinRegModel.params[4])\n",
    "\n",
    "plt.scatter(linRegModelAT.params[1], multipleLinRegModel.params[1], color = 'grey')\n",
    "plt.scatter(linRegModelV.params[1], multipleLinRegModel.params[2], color = 'black')\n",
    "plt.scatter(linRegModelAP.params[1], multipleLinRegModel.params[3], color = 'blue')\n",
    "plt.scatter(linRegModelRH.params[1], multipleLinRegModel.params[4], color = 'red')\n",
    "plt.ylabel('Multiple Regression Coefficients')\n",
    "plt.xlabel('Simple/Univariate Regression Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a1c4b-0a0b-4088-ba43-c496649513fc",
   "metadata": {},
   "source": [
    "# On comparing the results, we observe that the coefficients for the variables in multiple regression are less than the corresponding coefficients for the variables in simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb25fb-5d14-4272-9c02-ff2e54f2fa3c",
   "metadata": {},
   "source": [
    "# (1) (f) Finding Non Linear Association"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03dc6f-b4b4-4c84-af0b-706ff082b038",
   "metadata": {},
   "source": [
    "# Non-linear association for AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a88a3-d740-44e3-b8a2-31201cffefb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame1 = df['AT']\n",
    "polyFeat = PolynomialFeatures(degree = 3)\n",
    "dataFrame1 = pd.DataFrame(dataFrame1)\n",
    "at = polyFeat.fit_transform(dataFrame1)\n",
    "model = smf.ols('PE~at', df)\n",
    "linRegModelAT=model.fit()\n",
    "predictionsAT = linRegModelAT.predict(df)\n",
    "linRegModelAT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f68682-115d-49b9-b4f2-6600e2408644",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['AT'], df['PE'],color='grey')\n",
    "plt.plot(df['AT'], predictionsAT, color = 'black')\n",
    "plt.xlabel('Values for AT')\n",
    "plt.ylabel('Values for PE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a5d3a-8a3b-401a-9a51-8d31a4548f05",
   "metadata": {},
   "source": [
    "# Non-linear association for V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b83d38-caf9-466b-b161-bb607f7f6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame1 = df['V']\n",
    "polyFeat = PolynomialFeatures(degree = 3)\n",
    "dataFrame1 = pd.DataFrame(dataFrame1)\n",
    "v = polyFeat.fit_transform(dataFrame1)\n",
    "model = smf.ols('PE~v', df)\n",
    "linRegModelV=model.fit()\n",
    "predictionsV = linRegModelV.predict(df)\n",
    "linRegModelV.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cca0a-d53c-49da-81c2-3a7c494bf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['V'], df['PE'],color='grey')\n",
    "plt.plot(df['V'], predictionsV, color = 'black')\n",
    "plt.xlabel('Values for V')\n",
    "plt.ylabel('Values for PE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8d773-2e05-4b96-91e3-51e8b41fcb43",
   "metadata": {},
   "source": [
    "# Non-linear association for AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8d811-8f70-4905-9f54-6f9875a9709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame1 = df['AP']\n",
    "polyFeat = PolynomialFeatures(degree = 3)\n",
    "dataFrame1 = pd.DataFrame(dataFrame1)\n",
    "ap = polyFeat.fit_transform(dataFrame1)\n",
    "model = smf.ols('PE~ap', df)\n",
    "linRegModelAP=model.fit()\n",
    "predictionsAP = linRegModelAP.predict(df)\n",
    "linRegModelAP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b812b5-f076-4caf-906c-abf910cdabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['AP'], df['PE'],color='grey')\n",
    "plt.plot(df['AP'], predictionsAP, color = 'black')\n",
    "plt.xlabel('Values for AP')\n",
    "plt.ylabel('Values for PE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e71fe9-421b-438b-baaf-1a7eefb218e6",
   "metadata": {},
   "source": [
    "# Non-linear association for RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c3290-8393-403b-92d4-7c7a7a68f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame1 = df['RH']\n",
    "polyFeat = PolynomialFeatures(degree = 3)\n",
    "dataFrame1 = pd.DataFrame(dataFrame1)\n",
    "rh = polyFeat.fit_transform(dataFrame1)\n",
    "model = smf.ols('PE~rh', df)\n",
    "linRegModelRH=model.fit()\n",
    "predictionsRH = linRegModelRH.predict(df)\n",
    "linRegModelRH.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23aff8-2995-4ca9-8e01-f2b2ea241cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['RH'], df['PE'],color='grey')\n",
    "plt.plot(df['RH'], predictionsRH, color = 'black')\n",
    "plt.xlabel('Values for RH')\n",
    "plt.ylabel('Values for PE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641703b-02d2-40f2-8a6e-0bbd90a33013",
   "metadata": {},
   "source": [
    "# From the scatterplots above and the summary we can see that there is non-linear association of variables AT, AP and RH with PE as the p value is less than threshold(0.05). However, for V the p-value for v**2 is 0.768 which is higher than threshold(0.05) value, so there is no significant association between V and PE.Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb33b3-99be-46ea-b17a-e71e3a1da045",
   "metadata": {},
   "source": [
    "# (1) (g) Pairwise Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d59ff2-617b-41e7-a20f-8a6ad8a46431",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('PE~AT + V + AP + RH + (AT * RH) + (AT * AP) + (AT * V) + (V * AP) + (V * RH) + (AP * RH)', df)\n",
    "linRegModelPairs=model.fit()\n",
    "predictionsPairs = linRegModelPairs.predict(df)\n",
    "linRegModelPairs.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db807ed-28f2-4b5a-a39a-f681b0b6ced3",
   "metadata": {},
   "source": [
    "# We can see that the p values of the interactions (AT & RH), (AT & V), (V & AP) and (AP & RH) is below the threshold value of 0.05. Hence, we can say that there is association between some of the interactions of predictors with the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd2630e-bc88-445f-9239-f95e98074374",
   "metadata": {},
   "source": [
    "# (1) (h) Improving regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a411ec1-42cb-46a7-827a-aff2e680a60e",
   "metadata": {},
   "source": [
    "# Complete regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b02b8d0-b3c8-45e5-9c04-925f457fea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testingData = train_test_split(df, train_size = 0.7, random_state = 16)\n",
    "trainingDataX, testingDataX, trainingDataY, testingDataY = train_test_split(df.loc[:,'AT':'RH'], df['PE'], train_size = 0.7, random_state = 16)\n",
    "model = smf.ols('PE ~ AT + V + AP + RH', trainingData)\n",
    "linRegModel=model.fit()\n",
    "predictions = linRegModel.predict(trainingDataX)\n",
    "print('Training Mean Squared Error:', mean_squared_error(trainingDataY, predictions))\n",
    "\n",
    "predictions = linRegModel.predict(testingDataX)\n",
    "print('Testing Mean Squared Error:', mean_squared_error(testingDataY, predictions))\n",
    "\n",
    "linRegModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8cbfd6-4ceb-4b2d-8590-f42dfa30d344",
   "metadata": {},
   "source": [
    "# Regression model with all possible interactions and quadratic nonlinearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9cd7e-bf0c-4af3-8d36-dccde69eb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testingData = train_test_split(df, train_size = 0.7, random_state = 16)\n",
    "model = smf.ols('PE ~ AT + V + AP + RH + I(AT**2) + I(V**2) + I(AP**2) + I(RH**2) + (AT * V) + (AT * AP) + (AT * RH) + (V * AP) + (V * RH) + (AP * RH) + (AT * V * AP) + (AT * V * RH) + (AT * AP * RH) + (V * AP * RH) ', trainingData)\n",
    "linearModel=model.fit()\n",
    "predictions = linearModel.predict(trainingData)\n",
    "print('Training Mean Squared Error:', mean_squared_error(trainingDataY, predictions))\n",
    "\n",
    "predictions = linearModel.predict(testingData)\n",
    "print('Testing Mean Squared Error:', mean_squared_error(testingDataY, predictions))\n",
    "\n",
    "linearModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53edc175-f755-4a6e-a1a4-69079788ad72",
   "metadata": {},
   "source": [
    "# Using the summary above, we can remove the terms whose p value is greater than the threshold value 0.05 as those terms would not be significant for the model. Hence, we will remove RH , V**2 , AT:RH, AP:RH , V:RH , AT:V:RH , AT:AP:RH , V:AP:RH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda54c7d-28df-4836-b3c7-233afb9c2b09",
   "metadata": {},
   "source": [
    "model = smf.ols('PE ~ AT + V + AP + I(AT**2) + I(AP**2) + I(RH**2) + (AT * V) + (AT * AP) + (V * AP) + (AT * V * AP)', trainingData)\n",
    "linearModel2=model.fit()\n",
    "predictions = linearModel2.predict(trainingData)\n",
    "print('Training Mean Squared Error:', mean_squared_error(trainingDataY, predictions))\n",
    "\n",
    "predictions = linearModel2.predict(testingData)\n",
    "print('Testing Mean Squared Error:', mean_squared_error(testingDataY, predictions))\n",
    "\n",
    "linearModel2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e748edd-8494-42f5-96ff-9d43b3447bfb",
   "metadata": {},
   "source": [
    "# (1) (i) KNN RegressionÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7071326-3cff-4a8c-8b91-afa98dd3d253",
   "metadata": {},
   "source": [
    "# KNN without Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdde886-45fb-477f-8a12-8bb89c7cd8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainingDataX, testingDataX, trainingDataY, testingDataY = train_test_split(df.loc[:, 'AT':'RH'], df['PE'], train_size = 0.7, random_state = 16)\n",
    "\n",
    "testList = []\n",
    "trainList = []\n",
    "minK, minError = None, 1000000\n",
    "for k in range(1, 101):\n",
    "    knnModel = KNeighborsRegressor(n_neighbors = k)\n",
    "    knnModel.fit(trainingDataX, trainingDataY)\n",
    "    \n",
    "    predictions = knnModel.predict(testingDataX)\n",
    "    error = mean_squared_error(testingDataY, predictions)\n",
    "    if error < minError:\n",
    "        minK = k\n",
    "        minError = error\n",
    "    testList.append(error)\n",
    "    \n",
    "    predictions = knnModel.predict(trainingDataX)\n",
    "    error = mean_squared_error(trainingDataY, predictions)\n",
    "\n",
    "    trainList.append(error)\n",
    "\n",
    "kList = []\n",
    "for i in range(1, 101):\n",
    "    kList.append(1 / i)\n",
    "\n",
    "print(\"Using KNN the best k is\", minK, \"and the MSE is\", minError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d009dc-ad55-4987-b580-0ebc0c3c8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kList, testList, label = 'Test Error' , color = 'grey')\n",
    "plt.plot(kList, trainList, label = 'Train Error' , color = 'black')\n",
    "plt.ylabel('Mean Square Values')\n",
    "plt.xlabel('1 / k')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641960a-5108-40cd-86f5-646d76f4139a",
   "metadata": {},
   "source": [
    "# KNN After normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9d809-09db-4bef-a183-086536155a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "trainingDataXScaled = scaler.fit_transform(trainingDataX)\n",
    "testingDataXScaled = scaler.fit_transform(testingDataX)\n",
    "trainingDataX = pd.DataFrame(trainingDataXScaled)\n",
    "testingDataX = pd.DataFrame(testingDataXScaled)\n",
    "\n",
    "testList = []\n",
    "trainList = []\n",
    "minK, minError = None, 1000000\n",
    "for k in range(1, 101):\n",
    "    knnModel = KNeighborsRegressor(n_neighbors = k)\n",
    "    knnModel.fit(trainingDataX, trainingDataY)\n",
    "    \n",
    "    predictions = knnModel.predict(testingDataX)\n",
    "    error = mean_squared_error(testingDataY, predictions)\n",
    "    if error < minError:\n",
    "        minK = k\n",
    "        minError = error\n",
    "    testList.append(error)\n",
    "    \n",
    "    predictions = knnModel.predict(trainingDataX)\n",
    "    error = mean_squared_error(trainingDataY, predictions)\n",
    "\n",
    "    trainList.append(error)\n",
    "\n",
    "kList = []\n",
    "for i in range(1, 101):\n",
    "    kList.append(1 / i)\n",
    "\n",
    "print(\"Using KNN the best k is\", minK, \"and the MSE is\", minError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cf6e1-7923-49e6-b30e-766285be3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kList, testList, label = 'Test Error' , color = 'grey')\n",
    "plt.plot(kList, trainList, label = 'Train Error' , color = 'black')\n",
    "plt.ylabel('Mean Square Values')\n",
    "plt.xlabel('1 / k')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f7a0a-3f47-4e4f-bad4-e7ee08dcbaa6",
   "metadata": {},
   "source": [
    "# (1) (j) Summerizing results of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84255911-aaf9-4718-9087-304fc1df7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Model Type\", \"Test MSE\"]\n",
    "table = [[\"Complete Regression Model('AT', 'V', 'AP', 'RH')\", 20.925242451748257],[\"Regression Model(Before removing features)\", 17.743360480205084] , [\"Regression Model(After removing features)\", 17.80877502636172], [\"KNN without normalization\", 16.313661764193665], [\"KNN with normalization\", 14.786204622779518]]\n",
    "print(tabulate(table, headers = header, tablefmt = 'fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc03e02-e498-4bf8-88a9-dbeebe5f2353",
   "metadata": {},
   "source": [
    "# From the table above, we can see that KNN model with normalization performs better than all the other models, it has the least test mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a81bf-3544-462d-b17b-7879b4b623b9",
   "metadata": {},
   "source": [
    "# 2. ISLR: 2.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6439d9a-1383-4bb2-9ab9-bc0938d1e169",
   "metadata": {},
   "source": [
    "# 1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d84972-1a3a-49d0-a8e9-f8eab0f6eed9",
   "metadata": {},
   "source": [
    "# (a) The sample size n is extremely large, and the number of predic- tors p is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a33a0-bd28-4fcc-a5b0-90e8b284c7bd",
   "metadata": {},
   "source": [
    "Having a large sample size provides a lot of information about the underlying patterns in the data. Flexible methods can take advantage of this large sample size to fit complex models as they are less likely to overfit because there is large data to estimate the model parameters accurately. Therefore, flexible methods are generally expected to perform better than inflexible methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb37038-9451-469b-9f61-762817e12498",
   "metadata": {},
   "source": [
    "# (b) The number of predictors p is extremely large, and the number of observations n is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff566c1a-4165-442a-8a6a-6aa015b5493e",
   "metadata": {},
   "source": [
    "When having many predictors and a small sample size, there is a risk of overfitting with flexible models, as they may capture noise instead of meaningful patterns. In such situations, inflexible methods can be more suitable because they constrain the model complexity. So, inflexible methods are generally expected to perform better in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7797f-76ee-4db9-9761-e99f6235cecb",
   "metadata": {},
   "source": [
    "# (c) The relationship between the predictors and response is highly non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4d26a-a1e4-4835-b025-86d6e88421fd",
   "metadata": {},
   "source": [
    "When the relationship between predictors and the response variable is highly non-linear, flexible methods that can capture complex patterns are generally expected to perform better. Inflexible methods like linear regression may struggle to capture non-linearities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35102f26-1a2b-4891-9474-b9f19caaa004",
   "metadata": {},
   "source": [
    "# (d) The variance of the error terms, i.e. Ïƒ2 = Var(Îµ), is extremely high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3a681-284f-40bc-ae40-164dffdb219a",
   "metadata": {},
   "source": [
    "In situations with high error variance, flexible methods can fit the training data very closely, capturing both the signal and the noise in the data. This can lead to overfitting, where the model does not generalize well to new, unseen data. In such cases, inflexible methods, which are less sensitive to noise and have more stable predictions, may perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7433b-a893-4ba5-b669-453b6988a53a",
   "metadata": {},
   "source": [
    "# 2. ISLR: 2.4.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e73b475-869e-4101-86ee-055025368561",
   "metadata": {},
   "source": [
    "The table below provides a training data set containing six observations, three predictors, and one qualitative response variable.\n",
    "\n",
    " Obs.   X1   X2   X3     Y\n",
    "  1     0    3    0    Red\n",
    "  2     2    0    0    Red\n",
    "  3     0    1    3    Red\n",
    "  4     0    1    2   Green \n",
    "  5    âˆ’1    0    1   Green \n",
    "  6     1    1    1    Red\n",
    "  \n",
    "Suppose we wish to use this data set to make a prediction for Y when X1 = X2 = X3 = 0 using K-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8d8ce-61fb-4564-8bd2-afc4d5781334",
   "metadata": {},
   "source": [
    "# a) Compute the Euclidean distance between each observation and the test point,X1 =X2 =X3 =0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d800dfd-e752-4c64-8e5f-c1e997e30013",
   "metadata": {},
   "source": [
    "Test point = (0,0,0)\n",
    "\n",
    "For observation 1: (0,3,0)\n",
    "Euclidean Distance = sqrt( 0^2 + 3^2 + 0^2 ) = 3\n",
    "\n",
    "For observation 2: (2,0,0)\n",
    "Euclidean Distance = sqrt( 2^2 + 0^2 + 0^2 ) = 2\n",
    "\n",
    "For observation 3: (0,1,3)\n",
    "Euclidean Distance = sqrt( 0^2 + 1^2 + 3^2 ) = 3.16\n",
    "\n",
    "For observation 4: (0,1,2)\n",
    "Euclidean Distance = sqrt( 0^2 + 1^2 + 2^2 ) = 2.23\n",
    "\n",
    "For observation 5: (-1,0,1)\n",
    "Euclidean Distance = sqrt( (-1)^2 + 0^2 + 1^2 ) = 1.41\n",
    "\n",
    "For observation 6: (1,1,1)\n",
    "Euclidean Distance = sqrt( 1^2 + 1^2 + 1^2 ) = 1.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942e745-df17-4e00-accb-07a02cb2bfc3",
   "metadata": {},
   "source": [
    "# (b) What is our prediction with K = 1? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d094161-6f29-4f12-a724-9ff8fec48f9e",
   "metadata": {},
   "source": [
    "When K=1, the model will look at the point that is nearest to the test point. According to the above Euclidean distances, the nearest point is observation 5. Hence our model will predict the class of observation 5 ie. green"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14557c61-15c4-4f80-b640-caaf93106d84",
   "metadata": {},
   "source": [
    "# (c) What is our prediction with K = 3? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12996931-24d7-4c48-b1bf-01a5b22ee678",
   "metadata": {},
   "source": [
    "When K=3, the model will look at the 3 points that is nearest to the test point. According to the above Euclidean distances, the 3 nearest point are observation 5,6 and 2. The classes of these points are green, red and red respectively. Hence by majority our model will predict the class of the test point as red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c41ce6-8bfd-42ee-b897-d25ce70a1036",
   "metadata": {},
   "source": [
    "# (d) If the Bayes decision boundary in this problem is highly non- linear, then would we expect the best value for K to be large or small? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84524223-e8cc-46e5-be65-c1bb8a62db4d",
   "metadata": {},
   "source": [
    "The Bayes decision boundry is inversly propostional to K. If K increases, then the boundary becomes more rigid. Hence the value of K must be small for a good non - linear bayes decision boundary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
